{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e693e8-9d0e-437d-a876-f6a8a28f4a9b",
   "metadata": {},
   "source": [
    "Primeiro vamos definir a classe Dataset.\n",
    "Ela possui três métodos atualmente: gerarTreinamento, gerarTeste e gerarValidacao.\n",
    "Ambos os métodos retornam um par (textos, notas).\n",
    "O texto textos[i] tirou a nota notas[i]. \n",
    "textos[i] é uma lista de listas: um texto é uma lista de parágrafos.\n",
    "A competencia a ser avaliada é passada como parametro na criação do Dataset --- são 5 competencias (de 0 a 4), cada uma varia de 0 a 5 pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77eaf21f-c22b-4bc3-b728-f10779ec4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_dataset import Corpus\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "from skll import metrics as m\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, competence):\n",
    "        self.c = Corpus()\n",
    "        self.c.read_corpus().shape\n",
    "        self.train, self.valid, self.test = self.c.read_splits()\n",
    "        #print(self.train.shape)\n",
    "        self.train.loc[1:5, ['essay', 'score', 'competence']] \n",
    "        #print(self.valid.shape)\n",
    "        self.valid.loc[1:5, ['essay', 'score', 'competence']]\n",
    "        #print(self.test.shape)\n",
    "        self.test.loc[1:5, ['essay', 'score', 'competence']]\n",
    "        self.competence = competence\n",
    "    def UnirListas(self, lista):\n",
    "        unificado = \"\"\n",
    "        unificado = unificado+lista[0]+'\\n'\n",
    "        for t in range(1,len(lista)):\n",
    "            unificado += lista[t]+'\\n'\n",
    "        return unificado\n",
    "        \n",
    "    def gerarTreinamento(self):\n",
    "        \"\"\"\n",
    "        retorna um conjunto (texto, nota_competencia1). Um texto eh composto de varios paragrafos, cada paragrafo eh uma lista \n",
    "        \"\"\"\n",
    "        textos = []\n",
    "        notas = []\n",
    "        for index, row in self.train.iterrows():\n",
    "            texto = self.UnirListas(row['essay'])\n",
    "            notas.append( float(row['competence'][self.competence] / 40))\n",
    "            textos.append(texto)\n",
    "        return textos, notas\n",
    "    def gerarTeste(self):\n",
    "        textos = []\n",
    "        notas = []\n",
    "        for index, row in self.test.iterrows():\n",
    "            texto = self.UnirListas(row['essay'])\n",
    "            notas.append( float(row['competence'][self.competence] / 40))\n",
    "            textos.append(texto)\n",
    "        return textos, notas\n",
    "    def gerarValidacao(self):\n",
    "        textos = []\n",
    "        notas = []\n",
    "        for index, row in self.valid.iterrows():\n",
    "            texto = self.UnirListas(row['essay'])\n",
    "            notas.append( float(row['competence'][self.competence] / 40))\n",
    "            textos.append(texto)\n",
    "        return textos, notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e96aca-66e6-4d73-9d52-2fb5bd02f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(1)\n",
    "texto_treinamento, nota_treinamento = ds.gerarTreinamento()\n",
    "texto_teste, nota_teste = ds.gerarTeste()\n",
    "texto_valid, nota_valid = ds.gerarValidacao()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee70e7-14bc-4a61-aa77-abf52d50231b",
   "metadata": {},
   "source": [
    "Agora vamos importar o Tokenizer (o mesmo do BERT que usaremos), definiremos para usar a GPU se possível e definiremos a rede neural.\n",
    "\n",
    "A rede neural é: aplicar o BERT sobre a entrada gerando um vetor 1x768, por fim, uma camada densa de 768x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94239f43-7507-49c6-ad68-c18d27f351ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "modelo = 'xlm-roberta-large'\n",
    "#modelo = \"neuralmind/bert-large-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo,model_max_length=512, truncation=True, do_lower_case=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b149eb6-15be-49b5-91c2-650e808e6204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198\n",
      "3198\n"
     ]
    }
   ],
   "source": [
    "def TransformarTextoEmInput(textos):\n",
    "    tokenizados = []\n",
    "    for indice in range(len(textos)):\n",
    "            tokens = tokenizer.encode_plus(textos[indice], add_special_tokens=True, truncation=True, return_tensors='pt')\n",
    "            tokens = tokens['input_ids']\n",
    "            tokens = tokens.type(torch.int64).to(device)\n",
    "            tokenizados.append(tokens)\n",
    "    return tokenizados\n",
    "\n",
    "def TransformarNotasEmVetor(textos, notas):\n",
    "    novas_notas = []\n",
    "    for indice in range(len(textos)):\n",
    "            novas_notas.append(torch.tensor(notas[indice]).unsqueeze(0).to(device))\n",
    "    return novas_notas\n",
    "\n",
    "novos_inputs = TransformarTextoEmInput(texto_treinamento)\n",
    "print(len(novos_inputs))\n",
    "novas_notas = TransformarNotasEmVetor(texto_treinamento, nota_treinamento)\n",
    "print(len(novas_notas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10b6c41-8249-4be0-8098-4ef4da88fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(CustomModel,self).__init__() \n",
    "        self.model = AutoModel.from_pretrained(modelo).to(device)\n",
    "        self.classifier = nn.Sequential(nn.Linear(1024,1))\n",
    "    def forward(self, input_ids):\n",
    "        #print(\"Input: \", input_ids.size())\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids)\n",
    "            #outputs = torch.squeeze(outputs['pooler_output'])\n",
    "            outputs = outputs.last_hidden_state[0][0]\n",
    "        logits = self.classifier(outputs) \n",
    "        return logits\n",
    "model2 = CustomModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa54f48-afdd-4df1-bbf8-9e53a59030ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar(model, inputs, target):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    vetor_loss = []\n",
    "    optimizer.zero_grad()\n",
    "    count = 0\n",
    "    for index in range(len(inputs)):\n",
    "        count += 1\n",
    "        output = model(inputs[index])\n",
    "        #output = output.squeeze(0)\n",
    "        loss = loss_fn(output, target[index])\n",
    "        vetor_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        if (count == 1):    \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            count = 0\n",
    "    loss_tmp = sum(vetor_loss)/len(vetor_loss)\n",
    "    print(\"Loss media: \", loss_tmp)\n",
    "    \n",
    "def TokenizarUmParagrafo(paragrafo):\n",
    "    tokens = tokenizer.encode_plus(paragrafo, add_special_tokens=True, truncation=True, return_tensors='pt')\n",
    "    tokens = tokens['input_ids']\n",
    "    tokens = tokens.type(torch.int64).to(device)\n",
    "    return tokens\n",
    "\n",
    "def acuracia_classe(respostas, gold_labels):\n",
    "    classes_chutadas = [0]*6\n",
    "    classes_acertadas = [0]*6\n",
    "    classes_certas = [0]*6\n",
    "    porcentagem_final = []\n",
    "    for r, gl in zip(respostas, gold_labels):\n",
    "        #print(gl)\n",
    "        classes_certas[int(gl)] += 1\n",
    "        classes_chutadas[int(r)] += 1\n",
    "        if (r == gl):\n",
    "            classes_acertadas[int(r)] += 1\n",
    "    for acertos, certo in zip(classes_acertadas, classes_chutadas):\n",
    "        if certo != 0:\n",
    "            porcentagem_final.append( float(acertos) / certo )\n",
    "        else:\n",
    "            porcentagem_final.append(0.0)       \n",
    "    print(\"Chutei: \", classes_chutadas, sum(classes_chutadas))\n",
    "    print(\"Acertei: \", classes_acertadas, sum(classes_acertadas))\n",
    "    print(\"Dist: \", classes_certas, sum(classes_certas))\n",
    "    return porcentagem_final\n",
    "\n",
    "def testar(model, inputs, target):\n",
    "    respostas = []\n",
    "    for index in range(len(inputs)):\n",
    "        #notas_parciais = []\n",
    "        with torch.no_grad():\n",
    "            tokenizado = TokenizarUmParagrafo(inputs[index])\n",
    "            output = model(tokenizado)\n",
    "            nota = output.cpu().detach().numpy()\n",
    "            #notas_parciais.append(nota)\n",
    "            #print(len(notas_parciais))\n",
    "            #nota_final = np.rint(np.average(notas_parciais))\n",
    "            nota_final = np.rint(nota[0])\n",
    "        respostas.append(nota_final)\n",
    "    #print(respostas)\n",
    "    print(\"QWK: \", metrics.cohen_kappa_score(target, respostas, weights='quadratic'))\n",
    "    #print(\"RMSE: \", metrics.mean_squared_error(target, respostas, squared=False))\n",
    "    print(\"MSE: \", metrics.mean_squared_error(target, respostas, squared=True))\n",
    "    print(\"Porcentagem das classes: \", acuracia_classe(respostas, target))\n",
    "    print(\"Total acc: \", metrics.accuracy_score(target, respostas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50ba2a3-1e9c-4fa6-93aa-4f8f022b1d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracao  1\n",
      "Loss media:  0.8725155089316137\n",
      "-- Treinamento: \n",
      "QWK:  0.404487236402581\n",
      "MSE:  0.8223889931207005\n",
      "Chutei:  [0, 0, 112, 1451, 1613, 22] 3198\n",
      "Acertei:  [0, 0, 56, 694, 879, 2] 1631\n",
      "Dist:  [74, 60, 478, 1202, 1197, 187] 3198\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5, 0.47829083390764987, 0.5449473031618103, 0.09090909090909091]\n",
      "Total acc:  0.5100062539086929\n",
      "--Validacao:\n",
      "QWK:  0.38088651237690196\n",
      "MSE:  0.892128279883382\n",
      "Chutei:  [0, 0, 24, 313, 345, 4] 686\n",
      "Acertei:  [0, 0, 14, 156, 180, 1] 351\n",
      "Dist:  [20, 13, 101, 269, 244, 39] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5833333333333334, 0.4984025559105431, 0.5217391304347826, 0.25]\n",
      "Total acc:  0.5116618075801749\n",
      "--Teste:\n",
      "QWK:  0.3875367787648655\n",
      "MSE:  0.8236151603498543\n",
      "Chutei:  [0, 1, 18, 334, 328, 5] 686\n",
      "Acertei:  [0, 0, 10, 158, 185, 2] 355\n",
      "Dist:  [15, 6, 110, 240, 264, 51] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5555555555555556, 0.47305389221556887, 0.5640243902439024, 0.4]\n",
      "Total acc:  0.5174927113702624\n",
      "Iteracao  2\n",
      "Loss media:  0.7379453902861342\n",
      "-- Treinamento: \n",
      "QWK:  0.4497319158300044\n",
      "MSE:  0.7770481550969356\n",
      "Chutei:  [0, 0, 167, 1456, 1533, 42] 3198\n",
      "Acertei:  [0, 0, 90, 713, 853, 8] 1664\n",
      "Dist:  [74, 60, 478, 1202, 1197, 187] 3198\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5389221556886228, 0.4896978021978022, 0.5564253098499674, 0.19047619047619047]\n",
      "Total acc:  0.5203252032520326\n",
      "--Validacao:\n",
      "QWK:  0.4373277896980131\n",
      "MSE:  0.8236151603498543\n",
      "Chutei:  [0, 0, 40, 308, 334, 4] 686\n",
      "Acertei:  [0, 0, 26, 163, 178, 1] 368\n",
      "Dist:  [20, 13, 101, 269, 244, 39] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.65, 0.5292207792207793, 0.5329341317365269, 0.25]\n",
      "Total acc:  0.5364431486880467\n",
      "--Teste:\n",
      "QWK:  0.43584327934718947\n",
      "MSE:  0.7900874635568513\n",
      "Chutei:  [0, 0, 34, 322, 317, 13] 686\n",
      "Acertei:  [0, 0, 16, 154, 184, 5] 359\n",
      "Dist:  [15, 6, 110, 240, 264, 51] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.47058823529411764, 0.4782608695652174, 0.580441640378549, 0.38461538461538464]\n",
      "Total acc:  0.5233236151603499\n",
      "Iteracao  3\n",
      "Loss media:  0.713860467324198\n",
      "-- Treinamento: \n",
      "QWK:  0.4720311335587478\n",
      "MSE:  0.7507817385866167\n",
      "Chutei:  [0, 0, 185, 1433, 1537, 43] 3198\n",
      "Acertei:  [0, 0, 95, 716, 873, 9] 1693\n",
      "Dist:  [74, 60, 478, 1202, 1197, 187] 3198\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5135135135135135, 0.49965108164689465, 0.5679895901106051, 0.20930232558139536]\n",
      "Total acc:  0.5293933708567855\n",
      "--Validacao:\n",
      "QWK:  0.4397636695175736\n",
      "MSE:  0.826530612244898\n",
      "Chutei:  [0, 0, 46, 307, 328, 5] 686\n",
      "Acertei:  [0, 0, 27, 159, 174, 1] 361\n",
      "Dist:  [20, 13, 101, 269, 244, 39] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5869565217391305, 0.5179153094462541, 0.5304878048780488, 0.2]\n",
      "Total acc:  0.5262390670553936\n",
      "--Teste:\n",
      "QWK:  0.47233129108716077\n",
      "MSE:  0.7521865889212828\n",
      "Chutei:  [0, 0, 43, 306, 324, 13] 686\n",
      "Acertei:  [0, 0, 20, 150, 188, 4] 362\n",
      "Dist:  [15, 6, 110, 240, 264, 51] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.46511627906976744, 0.49019607843137253, 0.5802469135802469, 0.3076923076923077]\n",
      "Total acc:  0.5276967930029155\n",
      "Iteracao  4\n",
      "Loss media:  0.698641928971043\n",
      "-- Treinamento: \n",
      "QWK:  0.477819906547279\n",
      "MSE:  0.7473420888055035\n",
      "Chutei:  [0, 0, 198, 1415, 1539, 46] 3198\n",
      "Acertei:  [0, 0, 100, 712, 878, 9] 1699\n",
      "Dist:  [74, 60, 478, 1202, 1197, 187] 3198\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5050505050505051, 0.5031802120141343, 0.5705003248862898, 0.1956521739130435]\n",
      "Total acc:  0.5312695434646654\n",
      "--Validacao:\n",
      "QWK:  0.439116402495876\n",
      "MSE:  0.8309037900874635\n",
      "Chutei:  [0, 0, 48, 307, 325, 6] 686\n",
      "Acertei:  [0, 0, 28, 160, 172, 1] 361\n",
      "Dist:  [20, 13, 101, 269, 244, 39] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5833333333333334, 0.5211726384364821, 0.5292307692307693, 0.16666666666666666]\n",
      "Total acc:  0.5262390670553936\n",
      "--Teste:\n",
      "QWK:  0.4898504699979006\n",
      "MSE:  0.7332361516034985\n",
      "Chutei:  [0, 0, 44, 301, 326, 15] 686\n",
      "Acertei:  [0, 0, 21, 152, 192, 4] 369\n",
      "Dist:  [15, 6, 110, 240, 264, 51] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.4772727272727273, 0.5049833887043189, 0.588957055214724, 0.26666666666666666]\n",
      "Total acc:  0.5379008746355685\n",
      "Iteracao  5\n",
      "Loss media:  0.6875699890741145\n",
      "-- Treinamento: \n",
      "QWK:  0.485102973805032\n",
      "MSE:  0.7407754846779238\n",
      "Chutei:  [0, 0, 201, 1399, 1547, 51] 3198\n",
      "Acertei:  [0, 0, 100, 704, 879, 12] 1695\n",
      "Dist:  [74, 60, 478, 1202, 1197, 187] 3198\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.4975124378109453, 0.503216583273767, 0.5681965093729799, 0.23529411764705882]\n",
      "Total acc:  0.5300187617260788\n",
      "--Validacao:\n",
      "QWK:  0.4513060353523156\n",
      "MSE:  0.8206997084548106\n",
      "Chutei:  [0, 0, 50, 302, 326, 8] 686\n",
      "Acertei:  [0, 0, 31, 157, 171, 1] 360\n",
      "Dist:  [20, 13, 101, 269, 244, 39] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.62, 0.5198675496688742, 0.5245398773006135, 0.125]\n",
      "Total acc:  0.5247813411078717\n",
      "--Teste:\n",
      "QWK:  0.4899221924210637\n",
      "MSE:  0.7346938775510204\n",
      "Chutei:  [0, 0, 44, 296, 331, 15] 686\n",
      "Acertei:  [0, 0, 22, 149, 193, 4] 368\n",
      "Dist:  [15, 6, 110, 240, 264, 51] 686\n",
      "Porcentagem das classes:  [0.0, 0.0, 0.5, 0.5033783783783784, 0.5830815709969789, 0.26666666666666666]\n",
      "Total acc:  0.5364431486880467\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss_memoria' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-75f2e3de8f81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--Teste:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtestar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexto_teste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnota_teste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_memoria\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"QWK: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQWK_memoria\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RMSE: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSE_memoria\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_memoria' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Iteracao \", i+1)\n",
    "    treinar(model2, novos_inputs, novas_notas)\n",
    "    print(\"-- Treinamento: \")\n",
    "    testar(model2, texto_treinamento, nota_treinamento)\n",
    "    print(\"--Validacao:\")\n",
    "    testar(model2, texto_valid, nota_valid)\n",
    "    print(\"--Teste:\")\n",
    "    testar(model2, texto_teste, nota_teste)\n",
    "print(\"Loss: \", loss_memoria)\n",
    "print(\"QWK: \", QWK_memoria)\n",
    "print(\"RMSE: \", RMSE_memoria)\n",
    "print(\"Acc: \", ACC_memoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f32ee-a205-4838-a48e-9e9622ae377a",
   "metadata": {},
   "source": [
    "Aqui farei o baseline mais simples de todos: dizer o índice mais comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58564632-1d7f-4c43-aac9-744ce1dae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_most_common_index(novas_notas):\n",
    "    indices = [0,0,0,0,0,0]\n",
    "    for i in novas_notas:\n",
    "        indices[int(i)] += 1\n",
    "    maior_valor = -1\n",
    "    maior_indice = -1\n",
    "    print(indices)\n",
    "    for i in range(6):\n",
    "        if(indices[int(i)] > maior_valor):\n",
    "            maior_valor = indices[int(i)]\n",
    "            maior_indice = i\n",
    "    return maior_indice\n",
    "\n",
    "def test_most_common_index(index, notas):\n",
    "    acertos = 0\n",
    "    respostas = []\n",
    "    for i in notas:\n",
    "        respostas.append(index)\n",
    "    print(\"QWK1: \", m.kappa(notas, respostas, weights='quadratic'))\n",
    "    print(\"QWK2: \", metrics.cohen_kappa_score(notas, respostas, weights='quadratic'))\n",
    "    print(\"RMSE: \", metrics.mean_squared_error(notas, respostas, squared=False))\n",
    "    print(\"Acc: \", metrics.accuracy_score(notas, respostas))\n",
    "    #return (acertos/len(notas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f22ab8-54a1-4c1f-b7f9-7de02a589e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = learn_most_common_index(nota_treinamento)\n",
    "print(\"Treinamento:\")\n",
    "test_most_common_index(indice, nota_treinamento)\n",
    "print(\"Teste:\")\n",
    "test_most_common_index(indice, nota_teste)\n",
    "print(\"Validacao:\")\n",
    "test_most_common_index(indice, nota_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c9a51-10e1-49a6-93c1-0e826add8410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc002a-85ba-4e12-b28d-0d58d5e9fffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8e8f1-1fad-40d2-9aba-55a2621ecee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fafd9b-71b6-4bcc-be2c-835bd4eb03bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c980b92-eeb6-4bcf-a791-bf596df4f474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b11a5c-024a-4225-8c70-5bcc9eb50e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
